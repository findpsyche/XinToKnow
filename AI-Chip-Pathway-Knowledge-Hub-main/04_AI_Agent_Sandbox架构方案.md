# AI Agent Sandbox æ¶æ„æ–¹æ¡ˆ - å¤šèŠ¯ç‰‡é€‚é…çš„å¼ºåŒ–å­¦ä¹ ç¯å¢ƒ

## ğŸ“‹ é¡¹ç›®èƒŒæ™¯ä¸ç›®æ ‡

### ç”¨æˆ·æƒ³æ³•è¯„ä¼°

**æ ¸å¿ƒæ¦‚å¿µ**ï¼š
> æ ¹æ®ä¸åŒèŠ¯ç‰‡å¼€å‘é€‚é…çš„Sandboxï¼Œè®©å„ç§Agentsåœ¨Sandboxä¸­è‡ªä¸»å­¦ä¹ ï¼ˆRLï¼‰ï¼Œå¹¶æ ¹æ®ç”¨æˆ·éœ€æ±‚è‡ªæˆ‘è¯„ä¼°å’Œè¿›åŒ–ï¼Œæœ€ç»ˆè¿è¡Œåœ¨é€‚é…çš„èŠ¯ç‰‡ç¯å¢ƒä¸­ã€‚

### å¯è¡Œæ€§åˆ†æ âœ…

```infographic
infographic list-grid-badge-card
data
  title å¯è¡Œæ€§è¯„ä¼°
  items
    - label æŠ€æœ¯å¯è¡Œ
      desc OpenAI Gymç­‰æˆç†Ÿæ¡†æ¶å¯å€Ÿé‰´
      icon mdi:check-circle
    - label å¸‚åœºä»·å€¼
      desc è§£å†³AIèŠ¯ç‰‡ç”Ÿæ€ç¢ç‰‡åŒ–é—®é¢˜
      icon mdi:trending-up
    - label å®ç°éš¾åº¦
      desc ä¸­é«˜éš¾åº¦ï¼Œéœ€è¦ç¡¬ä»¶æŠ½è±¡å±‚è®¾è®¡
      icon mdi:gauge
    - label åˆ›æ–°æ€§
      desc èŠ¯ç‰‡æ„ŸçŸ¥çš„RLæ¡†æ¶ï¼Œå…·æœ‰æ–°é¢–æ€§
      icon mdi:lightbulb
```

**ç†ç”±**ï¼š
1. **æŠ€æœ¯æˆç†Ÿåº¦**ï¼šå¼ºåŒ–å­¦ä¹ æ¡†æ¶æˆç†Ÿï¼ˆGym, Ray RLlib, Stable-Baselines3ï¼‰
2. **ç¡¬ä»¶æŠ½è±¡**ï¼šæœ‰å…ˆä¾‹ï¼ˆCUDA/OpenCLæŠ½è±¡ã€ONNX Runtimeï¼‰
3. **å¸‚åœºéœ€æ±‚**ï¼šAIèŠ¯ç‰‡ç¢ç‰‡åŒ–éœ€è¦ç»Ÿä¸€å¼€å‘ç¯å¢ƒ
4. **å­¦æœ¯ä»·å€¼**ï¼šç¡¬ä»¶æ„ŸçŸ¥çš„RLè®­ç»ƒæ˜¯å‰æ²¿ç ”ç©¶æ–¹å‘

**æ½œåœ¨æŒ‘æˆ˜**ï¼š
- âš ï¸ ä¸åŒèŠ¯ç‰‡æ€§èƒ½å·®å¼‚å¤§ï¼Œéœ€è¦æ€§èƒ½è‡ªé€‚åº”
- âš ï¸ éœ€è¦è·å–å¤šç§èŠ¯ç‰‡çš„åº•å±‚SDKè®¿é—®æƒé™
- âš ï¸ RLè®­ç»ƒç¨³å®šæ€§å’Œæ•ˆç‡é—®é¢˜

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„

```infographic
infographic hierarchy-tree-curved-line-rounded-rect-node
data
  title Agent Sandbox ç³»ç»Ÿæ¶æ„
  items
    - label Agentå±‚
      children:
        - label RL Agents
        - label ç­–ç•¥ç½‘ç»œ
        - label ä»·å€¼ç½‘ç»œ
    - label Sandboxæ ¸å¿ƒå±‚
      children:
        - label ç¯å¢ƒæ¥å£
        - label å¥–åŠ±å‡½æ•°
        - label çŠ¶æ€ç®¡ç†
    - label ç¡¬ä»¶æŠ½è±¡å±‚ (HAL)
      children:
        - label NVIDIAé€‚é…å™¨
        - label AMDé€‚é…å™¨
        - label è‡ªç ”èŠ¯ç‰‡é€‚é…å™¨
    - label èŠ¯ç‰‡å±‚
      children:
        - label GPU/TPU
        - label ä¸“ç”¨AIèŠ¯ç‰‡
```

---

### æ ¸å¿ƒç»„ä»¶è¯¦è§£

#### 1. Agentæ¥å£å±‚

**è®¾è®¡ç›®æ ‡**ï¼šç»Ÿä¸€çš„Agent APIï¼Œæ”¯æŒå¤šç§RLç®—æ³•

```python
# ä¼ªä»£ç ç¤ºä¾‹
class BaseAgent(ABC):
    """AgentåŸºç±»"""
    
    @abstractmethod
    def select_action(self, observation):
        """æ ¹æ®è§‚æµ‹é€‰æ‹©åŠ¨ä½œ"""
        pass
    
    @abstractmethod
    def learn(self, experience):
        """ä»ç»éªŒä¸­å­¦ä¹ """
        pass
    
    @abstractmethod
    def evaluate(self, env, num_episodes):
        """è¯„ä¼°agentæ€§èƒ½"""
        pass
    
    @abstractmethod
    def save(self, path):
        """ä¿å­˜æ¨¡å‹"""
        pass
    
    @abstractmethod
    def load(self, path):
        """åŠ è½½æ¨¡å‹"""
        pass
```

**æ”¯æŒçš„Agentç±»å‹**ï¼š
- DQN (Deep Q-Network)
- PPO (Proximal Policy Optimization)
- SAC (Soft Actor-Critic)
- A3C (Asynchronous Advantage Actor-Critic)

---

#### 2. Sandboxç¯å¢ƒå±‚

**è®¾è®¡åŸåˆ™**ï¼šéµå¾ªOpenAI Gymæ¥å£è§„èŒƒ

```python
class ChipAwareSandbox(gym.Env):
    """èŠ¯ç‰‡æ„ŸçŸ¥çš„Sandboxç¯å¢ƒ"""
    
    def __init__(self, task_config, chip_config):
        """
        Args:
            task_config: ä»»åŠ¡é…ç½®ï¼ˆå¦‚æ¸¸æˆç±»å‹ã€ç›®æ ‡ï¼‰
            chip_config: èŠ¯ç‰‡é…ç½®ï¼ˆç±»å‹ã€èµ„æºé™åˆ¶ï¼‰
        """
        self.task = self._create_task(task_config)
        self.chip_adapter = ChipAdapterFactory.create(chip_config)
        
        # åŠ¨ä½œå’Œè§‚æµ‹ç©ºé—´
        self.action_space = self._define_action_space()
        self.observation_space = self._define_observation_space()
    
    def step(self, action):
        """æ‰§è¡Œä¸€æ­¥
        Returns:
            observation, reward, done, info
        """
        # åœ¨æŒ‡å®šèŠ¯ç‰‡ä¸Šæ‰§è¡Œè®¡ç®—
        with self.chip_adapter.context():
            observation = self.task.step(action)
            reward = self._compute_reward(observation)
            done = self.task.is_done()
            
            # æ·»åŠ èŠ¯ç‰‡æ€§èƒ½æŒ‡æ ‡
            info = {
                'chip_utilization': self.chip_adapter.get_utilization(),
                'latency': self.chip_adapter.get_latency(),
                'power': self.chip_adapter.get_power_usage()
            }
        
        return observation, reward, done, info
    
    def reset(self):
        """é‡ç½®ç¯å¢ƒ"""
        return self.task.reset()
    
    def _compute_reward(self, observation):
        """è®¡ç®—å¥–åŠ±ï¼ˆå¯åŒ…å«æ•ˆç‡å¥–åŠ±ï¼‰"""
        task_reward = self.task.get_reward()
        
        # èŠ¯ç‰‡æ•ˆç‡å¥–åŠ±ï¼ˆé¼“åŠ±é«˜æ•ˆåˆ©ç”¨ç¡¬ä»¶ï¼‰
        efficiency_reward = self._efficiency_bonus()
        
        return task_reward + efficiency_reward
    
    def _efficiency_bonus(self):
        """æ ¹æ®èŠ¯ç‰‡åˆ©ç”¨ç‡ç»™äºˆå¥–åŠ±"""
        util = self.chip_adapter.get_utilization()
        # åˆ©ç”¨ç‡åœ¨80-95%æ—¶å¥–åŠ±æœ€å¤§
        if 0.8 <= util <= 0.95:
            return 0.1
        return 0.0
```

---

#### 3. ç¡¬ä»¶æŠ½è±¡å±‚ (HAL)

**å…³é”®è®¾è®¡**ï¼šç»Ÿä¸€ä¸åŒèŠ¯ç‰‡çš„æ¥å£å·®å¼‚

```python
class ChipAdapter(ABC):
    """èŠ¯ç‰‡é€‚é…å™¨åŸºç±»"""
    
    @abstractmethod
    def initialize(self):
        """åˆå§‹åŒ–èŠ¯ç‰‡"""
        pass
    
    @abstractmethod
    def allocate_memory(self, size):
        """åˆ†é…æ˜¾å­˜/å†…å­˜"""
        pass
    
    @abstractmethod
    def execute_kernel(self, kernel, *args):
        """æ‰§è¡Œè®¡ç®—kernel"""
        pass
    
    @abstractmethod
    def synchronize(self):
        """åŒæ­¥è®¡ç®—"""
        pass
    
    @abstractmethod
    def get_utilization(self):
        """è·å–èŠ¯ç‰‡åˆ©ç”¨ç‡"""
        pass
    
    @abstractmethod
    def get_memory_info(self):
        """è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        pass


class NVIDIAAdapter(ChipAdapter):
    """NVIDIA GPUé€‚é…å™¨"""
    
    def __init__(self, device_id=0):
        self.device = torch.device(f'cuda:{device_id}')
        self.initialize()
    
    def initialize(self):
        torch.cuda.init()
        self.properties = torch.cuda.get_device_properties(self.device)
    
    def execute_kernel(self, kernel, *args):
        """ä½¿ç”¨PyTorch/CUDAæ‰§è¡Œ"""
        with torch.cuda.device(self.device):
            return kernel(*args)
    
    def get_utilization(self):
        """é€šè¿‡NVMLè·å–GPUåˆ©ç”¨ç‡"""
        import pynvml
        pynvml.nvmlInit()
        handle = pynvml.nvmlDeviceGetHandleByIndex(self.device.index)
        util = pynvml.nvmlDeviceGetUtilizationRates(handle)
        return util.gpu / 100.0


class CustomChipAdapter(ChipAdapter):
    """è‡ªç ”èŠ¯ç‰‡é€‚é…å™¨ï¼ˆæ›¦æœ›sunriseï¼‰"""
    
    def __init__(self, sdk_path):
        """
        Args:
            sdk_path: è‡ªç ”èŠ¯ç‰‡SDKè·¯å¾„
        """
        import sys
        sys.path.append(sdk_path)
        import custom_chip_sdk  # å‡è®¾çš„SDK
        
        self.sdk = custom_chip_sdk
        self.initialize()
    
    def execute_kernel(self, kernel, *args):
        """é€šè¿‡SDKæ‰§è¡Œè®¡ç®—"""
        # éœ€è¦æ ¹æ®å®é™…SDK APIè°ƒæ•´
        return self.sdk.run_inference(kernel, *args)


class ChipAdapterFactory:
    """é€‚é…å™¨å·¥å‚"""
    
    @staticmethod
    def create(chip_config):
        chip_type = chip_config['type']
        
        if chip_type == 'nvidia':
            return NVIDIAAdapter(chip_config.get('device_id', 0))
        elif chip_type == 'amd':
            return AMDAdapter(chip_config)
        elif chip_type == 'custom':
            return CustomChipAdapter(chip_config['sdk_path'])
        else:
            raise ValueError(f"Unsupported chip type: {chip_type}")
```

---

#### 4. è‡ªé€‚åº”å­¦ä¹ æ¨¡å—

**æ ¸å¿ƒåŠŸèƒ½**ï¼šæ ¹æ®èŠ¯ç‰‡æ€§èƒ½è°ƒæ•´è®­ç»ƒç­–ç•¥

```python
class AdaptiveLearner:
    """èŠ¯ç‰‡è‡ªé€‚åº”å­¦ä¹ å™¨"""
    
    def __init__(self, agent, sandbox):
        self.agent = agent
        self.sandbox = sandbox
        self.chip_profile = self._profile_chip()
    
    def _profile_chip(self):
        """æ€§èƒ½ç”»åƒ"""
        # è¿è¡Œbenchmarkæµ‹è¯•èŠ¯ç‰‡æ€§èƒ½
        return {
            'compute_capability': self._benchmark_compute(),
            'memory_bandwidth': self._benchmark_memory(),
            'optimal_batch_size': self._find_optimal_batch_size()
        }
    
    def train(self, num_steps):
        """è‡ªé€‚åº”è®­ç»ƒ"""
        # æ ¹æ®èŠ¯ç‰‡èƒ½åŠ›è°ƒæ•´è¶…å‚æ•°
        batch_size = self.chip_profile['optimal_batch_size']
        
        for step in range(num_steps):
            # æ”¶é›†ç»éªŒ
            batch = self._collect_experience(batch_size)
            
            # å­¦ä¹ ï¼ˆåœ¨èŠ¯ç‰‡ä¸Šæ‰§è¡Œï¼‰
            loss = self.agent.learn(batch)
            
            # åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡
            if step % 1000 == 0:
                self._adjust_hyperparameters()
    
    def _adjust_hyperparameters(self):
        """æ ¹æ®æ€§èƒ½åŠ¨æ€è°ƒæ•´"""
        util = self.sandbox.chip_adapter.get_utilization()
        
        if util < 0.5:
            # åˆ©ç”¨ç‡ä½ï¼Œå¢åŠ batch size
            self.agent.increase_batch_size()
        elif util > 0.95:
            # åˆ©ç”¨ç‡è¿‡é«˜ï¼Œå‡å°‘batch size
            self.agent.decrease_batch_size()
```

---

## ğŸ¯ å®ç°è·¯çº¿å›¾

```infographic
infographic sequence-snake-steps-simple
data
  title å¼€å‘è·¯çº¿å›¾
  items
    - label ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€æ¡†æ¶
      desc å®ç°Gymå…¼å®¹çš„Sandboxæ¥å£
    - label ç¬¬äºŒé˜¶æ®µï¼šå•èŠ¯ç‰‡é€‚é…
      desc å®ŒæˆNVIDIA GPUé€‚é…å™¨
    - label ç¬¬ä¸‰é˜¶æ®µï¼šAgenté›†æˆ
      desc é›†æˆPPO/DQNç®—æ³•
    - label ç¬¬å››é˜¶æ®µï¼šå¤šèŠ¯ç‰‡æ”¯æŒ
      desc æ·»åŠ AMD/è‡ªç ”èŠ¯ç‰‡é€‚é…
    - label ç¬¬äº”é˜¶æ®µï¼šè‡ªé€‚åº”ä¼˜åŒ–
      desc å®ç°èŠ¯ç‰‡æ„ŸçŸ¥çš„è®­ç»ƒç­–ç•¥
    - label ç¬¬å…­é˜¶æ®µï¼šè¯„ä¼°ç³»ç»Ÿ
      desc æ„å»ºAgentè‡ªåŠ¨è¯„ä¼°æ¡†æ¶
```

---

## ğŸ› ï¸ æŠ€æœ¯æ ˆé€‰æ‹©

### æ ¸å¿ƒæ¡†æ¶

| ç»„ä»¶ | æŠ€æœ¯é€‰å‹ | ç†ç”± |
|------|---------|------|
| RLæ¡†æ¶ | Stable-Baselines3 | æ˜“ç”¨ã€æ–‡æ¡£å®Œå–„ã€æ”¯æŒå¤šç§ç®—æ³• |
| ç¯å¢ƒæ¥å£ | OpenAI Gym | ä¸šç•Œæ ‡å‡† |
| æ·±åº¦å­¦ä¹  | PyTorch 2.0+ | çµæ´»ã€ç¤¾åŒºæ´»è·ƒã€æ›¦æœ›å¯èƒ½ä½¿ç”¨ |
| åˆ†å¸ƒå¼è®­ç»ƒ | Ray RLlib (å¯é€‰) | æ‰©å±•æ€§å¥½ |
| ç¡¬ä»¶ç›‘æ§ | pynvml, py3nvml | GPUç›‘æ§ |
| é…ç½®ç®¡ç† | Hydra | å®éªŒé…ç½®ç®¡ç† |

### ä¾èµ–åº“

```python
# requirements.txt
torch>=2.0.0
gymnasium>=0.28.0  # Gymçš„æ–°ç‰ˆæœ¬
stable-baselines3>=2.0.0
tensorboard>=2.13.0
hydra-core>=1.3.0
pynvml>=11.5.0
numpy>=1.24.0
opencv-python>=4.8.0  # å¦‚éœ€å›¾åƒè§‚æµ‹
```

---

## ğŸ“ æœ€å°å¯è¡Œäº§å“ (MVP)

### MVPåŠŸèƒ½èŒƒå›´

**ç¬¬1ç‰ˆæœ¬ç›®æ ‡**ï¼ˆ2å‘¨å†…å®Œæˆï¼‰ï¼š

1. **ç®€å•ç¯å¢ƒ**ï¼šCartPole-v1ï¼ˆç»å…¸RLæµ‹è¯•ç¯å¢ƒï¼‰
2. **å•ä¸€èŠ¯ç‰‡**ï¼šNVIDIA GPUæ”¯æŒ
3. **å•ä¸€ç®—æ³•**ï¼šPPO
4. **åŸºç¡€ç›‘æ§**ï¼šGPUåˆ©ç”¨ç‡ã€è®­ç»ƒæ›²çº¿

### MVPä»£ç ç»“æ„

```
agent-sandbox/
â”œâ”€â”€ sandbox/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py              # Sandboxæ ¸å¿ƒç±»
â”‚   â””â”€â”€ envs/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ cartpole.py      # CartPoleç¯å¢ƒ
â”œâ”€â”€ adapters/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py              # é€‚é…å™¨åŸºç±»
â”‚   â””â”€â”€ nvidia.py            # NVIDIAé€‚é…å™¨
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ppo_agent.py         # PPO Agent
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ monitor.py           # æ€§èƒ½ç›‘æ§
â”‚   â””â”€â”€ config.py            # é…ç½®ç®¡ç†
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ train_cartpole.py    # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_adapter.py
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ cartpole.yaml        # Hydraé…ç½®
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§ª å®éªŒä¸Demoæ–¹æ¡ˆ

### å®éªŒä¸€ï¼šåŸºå‡†æµ‹è¯•

**ç›®æ ‡**ï¼šéªŒè¯ä¸åŒèŠ¯ç‰‡ä¸Šçš„è®­ç»ƒæ•ˆç‡

**æ­¥éª¤**ï¼š
1. åœ¨NVIDIA GPUä¸Šè®­ç»ƒPPOè§£å†³CartPole
2. è®°å½•ï¼šè®­ç»ƒæ—¶é—´ã€GPUåˆ©ç”¨ç‡ã€æœ€ç»ˆæ€§èƒ½
3. ï¼ˆå¦‚æœ‰æ¡ä»¶ï¼‰åœ¨AMD GPUä¸Šé‡å¤
4. å¯¹æ¯”åˆ†æ

**é¢„æœŸç»“æœ**ï¼š
- ç”Ÿæˆæ€§èƒ½å¯¹æ¯”æŠ¥å‘Š
- å¯è§†åŒ–è®­ç»ƒæ›²çº¿

---

### å®éªŒäºŒï¼šèŠ¯ç‰‡æ„ŸçŸ¥ä¼˜åŒ–

**ç›®æ ‡**ï¼šè¯æ˜ç¡¬ä»¶æ„ŸçŸ¥ç­–ç•¥çš„ä¼˜åŠ¿

**å¯¹æ¯”ç»„**ï¼š
- **åŸºçº¿**ï¼šå›ºå®šbatch sizeè®­ç»ƒ
- **å®éªŒç»„**ï¼šåŠ¨æ€è°ƒæ•´batch sizeï¼ˆæ ¹æ®GPUåˆ©ç”¨ç‡ï¼‰

**è¯„ä¼°æŒ‡æ ‡**ï¼š
- æ”¶æ•›é€Ÿåº¦
- æœ€ç»ˆæ€§èƒ½
- ç¡¬ä»¶åˆ©ç”¨ç‡

---

### å®éªŒä¸‰ï¼šå¤æ‚ç¯å¢ƒæ‰©å±•

**ç¯å¢ƒé€‰æ‹©**ï¼š
- Atariæ¸¸æˆï¼ˆPong, Breakoutï¼‰
- MuJoCoç‰©ç†ä»¿çœŸï¼ˆå¦‚æœ‰è®¸å¯è¯ï¼‰

**ç›®æ ‡**ï¼š
- éªŒè¯æ¡†æ¶æ‰©å±•æ€§
- å±•ç¤ºè§†è§‰è¾“å…¥å¤„ç†èƒ½åŠ›

---

### Demoå±•ç¤ºæ–¹æ¡ˆ

#### Demo 1ï¼šå®æ—¶å¯è§†åŒ–è®­ç»ƒ

**å·¥å…·**ï¼šTensorBoard + Gymnasiumæ¸²æŸ“

**å±•ç¤ºå†…å®¹**ï¼š
1. å·¦ä¾§ï¼šAgentå®æ—¶ç©CartPoleçš„è§†é¢‘
2. å³ä¾§ï¼š
   - å¥–åŠ±æ›²çº¿
   - GPUåˆ©ç”¨ç‡å®æ—¶ç›‘æ§
   - Lossæ›²çº¿

**å®ç°**ï¼š
```python
# ä¼ªä»£ç 
from torch.utils.tensorboard import SummaryWriter

writer = SummaryWriter('runs/cartpole_demo')

for episode in range(1000):
    obs = env.reset()
    done = False
    total_reward = 0
    
    while not done:
        action = agent.select_action(obs)
        obs, reward, done, info = env.step(action)
        total_reward += reward
        
        # è®°å½•åˆ°TensorBoard
        writer.add_scalar('GPU/Utilization', 
                         info['chip_utilization'], 
                         episode)
    
    writer.add_scalar('Reward', total_reward, episode)
```

**å±•ç¤ºæ•ˆæœ**ï¼š
- æµè§ˆå™¨æ‰“å¼€TensorBoardç•Œé¢
- å®æ—¶çœ‹åˆ°Agentä»å¤±è´¥åˆ°æˆåŠŸçš„è¿‡ç¨‹
- åŒæ—¶ç›‘æ§ç¡¬ä»¶æ€§èƒ½

---

#### Demo 2ï¼šå¤šèŠ¯ç‰‡å¯¹æ¯”Dashboard

**å·¥å…·**ï¼šStreamlit / Gradio

**ç•Œé¢è®¾è®¡**ï¼š
```
é€‰æ‹©èŠ¯ç‰‡: [NVIDIA GPU v] [AMD GPU] [Custom Chip]
é€‰æ‹©ç¯å¢ƒ: [CartPole v] [Atari]
é€‰æ‹©ç®—æ³•: [PPO v] [DQN]

[å¼€å§‹è®­ç»ƒ] [åœæ­¢]

å®æ—¶å›¾è¡¨ï¼š
+------------------+------------------+
| å¥–åŠ±æ›²çº¿          | ç¡¬ä»¶åˆ©ç”¨ç‡        |
+------------------+------------------+
| æ¨ç†å»¶è¿Ÿ          | è®­ç»ƒé€Ÿåº¦          |
+------------------+------------------+

è®­ç»ƒæ—¥å¿—ï¼š
[INFO] Episode 100: Reward = 195.3
[INFO] GPU Utilization: 87%
...
```

**ä»£ç ç¤ºä¾‹**ï¼ˆStreamlitï¼‰ï¼š
```python
import streamlit as st

st.title("AI Agent Sandbox - Multi-Chip Training")

chip = st.selectbox("é€‰æ‹©èŠ¯ç‰‡", ["NVIDIA", "AMD", "Custom"])
env_name = st.selectbox("é€‰æ‹©ç¯å¢ƒ", ["CartPole", "Atari-Pong"])

if st.button("å¼€å§‹è®­ç»ƒ"):
    # åˆ›å»ºé…ç½®
    config = {
        'chip': {'type': chip.lower()},
        'env': env_name
    }
    
    # å®æ—¶æ›´æ–°
    placeholder = st.empty()
    
    for episode in train_agent(config):
        with placeholder.container():
            col1, col2 = st.columns(2)
            with col1:
                st.line_chart(episode['rewards'])
            with col2:
                st.metric("GPUåˆ©ç”¨ç‡", f"{episode['gpu_util']:.1%}")
```

---

#### Demo 3ï¼šAgentæ€§èƒ½è¯„ä¼°æŠ¥å‘Š

**è‡ªåŠ¨ç”ŸæˆMarkdownæŠ¥å‘Š**

**æŠ¥å‘Šå†…å®¹**ï¼š
```markdown
# Agentè®­ç»ƒæŠ¥å‘Š

## ç¯å¢ƒé…ç½®
- ç¯å¢ƒï¼šCartPole-v1
- èŠ¯ç‰‡ï¼šNVIDIA RTX 3090
- ç®—æ³•ï¼šPPO

## è®­ç»ƒç»“æœ
- è®­ç»ƒè½®æ•°ï¼š1000 episodes
- å¹³å‡å¥–åŠ±ï¼š195.8 Â± 2.1
- æ”¶æ•›è½®æ•°ï¼šEpisode 342

## æ€§èƒ½æŒ‡æ ‡
| æŒ‡æ ‡ | å€¼ |
|------|---|
| å¹³å‡GPUåˆ©ç”¨ç‡ | 82.3% |
| è®­ç»ƒæ€»æ—¶é•¿ | 15åˆ†23ç§’ |
| æ¯episodeè€—æ—¶ | 0.92ç§’ |

## å¯è§†åŒ–
![è®­ç»ƒæ›²çº¿](./plots/reward_curve.png)
![GPUç›‘æ§](./plots/gpu_util.png)

## ç»“è®º
AgentæˆåŠŸå­¦ä¹ ä»»åŠ¡ï¼Œç¡¬ä»¶åˆ©ç”¨ç‡è‰¯å¥½ã€‚
```

---

## ğŸ”¬ åç»­å¼€å‘æ–¹å‘

### æ–¹å‘ä¸€ï¼šå¤šAgentååŒ

**æ‰©å±•**ï¼šæ”¯æŒå¤šä¸ªAgentåœ¨åŒä¸€ç¯å¢ƒä¸­ç«äº‰/åä½œ

**åº”ç”¨åœºæ™¯**ï¼š
- å¤šæ™ºèƒ½ä½“åšå¼ˆï¼ˆå¦‚Dota, StarCraftï¼‰
- åˆ†å¸ƒå¼ä¼˜åŒ–é—®é¢˜

**æŠ€æœ¯è¦ç‚¹**ï¼š
- é€šä¿¡åè®®è®¾è®¡
- å¥–åŠ±åˆ†é…æœºåˆ¶

---

### æ–¹å‘äºŒï¼šè¿ç§»å­¦ä¹ 

**ç›®æ ‡**ï¼šAgentåœ¨ä¸€ç§èŠ¯ç‰‡ä¸Šè®­ç»ƒï¼Œè¿ç§»åˆ°å¦ä¸€ç§èŠ¯ç‰‡

**ç ”ç©¶é—®é¢˜**ï¼š
- å¦‚ä½•æœ€å°åŒ–æ€§èƒ½æŸå¤±ï¼Ÿ
- ç¡¬ä»¶æ„ŸçŸ¥çš„æ¨¡å‹æ¶æ„è®¾è®¡

**å®éªŒæ–¹æ¡ˆ**ï¼š
1. åœ¨NVIDIA GPUä¸Šè®­ç»ƒ
2. å¯¼å‡ºæ¨¡å‹
3. åœ¨è‡ªç ”èŠ¯ç‰‡ä¸Šfine-tune
4. å¯¹æ¯”æ€§èƒ½

---

### æ–¹å‘ä¸‰ï¼šAutoMLé›†æˆ

**è‡ªåŠ¨åŒ–**ï¼š
- è‡ªåŠ¨è¶…å‚æ•°æœç´¢ï¼ˆé’ˆå¯¹ç‰¹å®šèŠ¯ç‰‡ï¼‰
- ç¥ç»æ¶æ„æœç´¢ï¼ˆNASï¼‰

**å·¥å…·é›†æˆ**ï¼š
- Optuna (è¶…å‚æ•°ä¼˜åŒ–)
- Ray Tune (åˆ†å¸ƒå¼è°ƒä¼˜)

---

### æ–¹å‘å››ï¼šè¾¹ç¼˜è®¾å¤‡æ”¯æŒ

**æ‰©å±•åˆ°è¾¹ç¼˜AIèŠ¯ç‰‡**ï¼š
- NVIDIA Jetson
- Google Coral
- åä¸ºæ˜‡è…¾310

**æŒ‘æˆ˜**ï¼š
- èµ„æºå—é™ç¯å¢ƒ
- å®æ—¶æ€§è¦æ±‚

---

## ğŸ“Š æˆåŠŸæŒ‡æ ‡

### æŠ€æœ¯æŒ‡æ ‡

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | æµ‹é‡æ–¹æ³• |
|------|--------|---------|
| èŠ¯ç‰‡é€‚é…æ—¶é—´ | < 2å¤© | æ–°å¢èŠ¯ç‰‡åˆ°å¯è¿è¡Œ |
| è®­ç»ƒæ•ˆç‡ | > 80% GPUåˆ©ç”¨ç‡ | NVMLç›‘æ§ |
| APIç¨³å®šæ€§ | 0 breaking changes | ç‰ˆæœ¬æµ‹è¯• |
| æ–‡æ¡£è¦†ç›–ç‡ | > 90% | Sphinxæ–‡æ¡£ |

### å­¦æœ¯æŒ‡æ ‡ï¼ˆé•¿æœŸï¼‰

- [ ] å‘è¡¨workshopè®ºæ–‡
- [ ] å¼€æºè·å¾—100+ stars
- [ ] è¢«å…¶ä»–ç ”ç©¶å¼•ç”¨

---

## ğŸ“ å­¦ä¹ ä»·å€¼

### å¯¹å²—ä½çš„å¸®åŠ©

```infographic
infographic list-row-simple-horizontal-arrow
data
  title é¡¹ç›®å¯¹å²—ä½çš„ä»·å€¼
  items
    - label SDKå¼€å‘ç»éªŒ
      desc ç¡¬ä»¶æŠ½è±¡å±‚è®¾è®¡
    - label å¤šèŠ¯ç‰‡é€‚é…
      desc ç›´æ¥å¯¹åº”å²—ä½èŒè´£
    - label æ€§èƒ½æµ‹è¯•
      desc ç›‘æ§ä¸ä¼˜åŒ–èƒ½åŠ›
    - label æ–‡æ¡£æ’°å†™
      desc APIæ–‡æ¡£ã€æµ‹è¯•æŠ¥å‘Š
    - label åˆ›æ–°æ€ç»´
      desc å±•ç¤ºè§£å†³é—®é¢˜èƒ½åŠ›
```

### æŠ€æœ¯æˆé•¿

- **ç³»ç»Ÿè®¾è®¡èƒ½åŠ›**ï¼šå¤§å‹é¡¹ç›®æ¶æ„ç»éªŒ
- **ç¡¬ä»¶ç†è§£**ï¼šæ·±å…¥èŠ¯ç‰‡å±‚é¢ä¼˜åŒ–
- **RLå®è·µ**ï¼šå‰æ²¿AIæŠ€æœ¯åº”ç”¨
- **å·¥ç¨‹èƒ½åŠ›**ï¼šå®Œæ•´é¡¹ç›®ç”Ÿå‘½å‘¨æœŸ

---

## ğŸ“š å‚è€ƒèµ„æº

### å¼€æºé¡¹ç›®å‚è€ƒ

1. **OpenAI Gym**
   - https://github.com/openai/gym
   - å­¦ä¹ ï¼šç¯å¢ƒæ¥å£è®¾è®¡

2. **Stable-Baselines3**
   - https://github.com/DLR-RM/stable-baselines3
   - å­¦ä¹ ï¼šRLç®—æ³•å®ç°

3. **Ray RLlib**
   - https://docs.ray.io/en/latest/rllib/index.html
   - å­¦ä¹ ï¼šåˆ†å¸ƒå¼è®­ç»ƒæ¶æ„

4. **ONNX Runtime**
   - https://github.com/microsoft/onnxruntime
   - å­¦ä¹ ï¼šç¡¬ä»¶æŠ½è±¡å±‚è®¾è®¡

### å­¦æœ¯è®ºæ–‡

1. **Hardware-aware Neural Architecture Search**
   - ç ”ç©¶ç¡¬ä»¶æ„ŸçŸ¥çš„æ¨¡å‹è®¾è®¡

2. **Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better**
   - æ¨¡å‹ä¼˜åŒ–ç»¼è¿°

---

## âœ… è¡ŒåŠ¨æ¸…å•

### ç«‹å³å¼€å§‹ï¼ˆç¬¬1-2å‘¨ï¼‰

- [ ] æ­å»ºå¼€å‘ç¯å¢ƒ
- [ ] å®ç°CartPole + NVIDIAé€‚é…å™¨
- [ ] è®­ç»ƒç¬¬ä¸€ä¸ªAgent
- [ ] å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹

### çŸ­æœŸç›®æ ‡ï¼ˆç¬¬3-4å‘¨ï¼‰

- [ ] æ·»åŠ Atariç¯å¢ƒæ”¯æŒ
- [ ] å®ç°DQNç®—æ³•
- [ ] æ€§èƒ½ç›‘æ§Dashboard
- [ ] æ’°å†™æŠ€æœ¯æ–‡æ¡£

### ä¸­æœŸç›®æ ‡ï¼ˆç¬¬5-8å‘¨ï¼‰

- [ ] å¤šèŠ¯ç‰‡æ”¯æŒï¼ˆå¦‚æœ‰æ¡ä»¶ï¼‰
- [ ] è‡ªé€‚åº”å­¦ä¹ æ¨¡å—
- [ ] å®Œæ•´çš„å•å…ƒæµ‹è¯•
- [ ] å½•åˆ¶Demoè§†é¢‘

### é•¿æœŸç›®æ ‡ï¼ˆç¬¬9-16å‘¨ï¼‰

- [ ] å¼€æºå‘å¸ƒ
- [ ] æ’°å†™æŠ€æœ¯åšå®¢
- [ ] å°è¯•å‘è¡¨è®ºæ–‡
- [ ] ç”¨äºå²—ä½é¢è¯•å±•ç¤º

---

## ğŸ¯ é¢è¯•å±•ç¤ºè¦ç‚¹

### Demoæ¼”ç¤ºè„šæœ¬ï¼ˆ5åˆ†é’Ÿï¼‰

1. **é—®é¢˜å¼•å…¥**ï¼ˆ30ç§’ï¼‰
   - "AIèŠ¯ç‰‡ç¢ç‰‡åŒ–ï¼Œå¼€å‘è€…éœ€è¦ä¸ºæ¯ç§èŠ¯ç‰‡é‡å†™ä»£ç "

2. **æ–¹æ¡ˆå±•ç¤º**ï¼ˆ1åˆ†é’Ÿï¼‰
   - "æˆ‘è®¾è®¡äº†ä¸€ä¸ªç¡¬ä»¶æŠ½è±¡çš„Agent Sandbox"
   - å±•ç¤ºæ¶æ„å›¾

3. **å®æ—¶Demo**ï¼ˆ2åˆ†é’Ÿï¼‰
   - å¯åŠ¨è®­ç»ƒï¼Œå±•ç¤ºå®æ—¶ç›‘æ§
   - åˆ‡æ¢èŠ¯ç‰‡é…ç½®ï¼Œé‡æ–°è®­ç»ƒ
   - å¯¹æ¯”æ€§èƒ½å·®å¼‚

4. **æŠ€æœ¯äº®ç‚¹**ï¼ˆ1åˆ†é’Ÿï¼‰
   - ç¡¬ä»¶æ„ŸçŸ¥çš„å¥–åŠ±å‡½æ•°
   - è‡ªé€‚åº”batch sizeè°ƒæ•´
   - æ€§èƒ½æå‡æ•°æ®

5. **æ€»ç»“**ï¼ˆ30ç§’ï¼‰
   - å±•ç¤ºå­¦åˆ°çš„æŠ€èƒ½ï¼ˆSDKå¼€å‘ã€æ€§èƒ½ä¼˜åŒ–ã€èŠ¯ç‰‡é€‚é…ï¼‰
   - å¦‚ä½•åº”ç”¨åˆ°å²—ä½

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**æœ€åæ›´æ–°**ï¼š2026-01-07  
**é¡¹ç›®çŠ¶æ€**ï¼šæ¶æ„è®¾è®¡é˜¶æ®µ  
**ä¸‹ä¸€æ­¥**ï¼šå®ç°MVPåŸå‹
