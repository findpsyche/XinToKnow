

## ğŸ“‹ æ–‡æ¡£å¯¼èˆª

### æ ¸å¿ƒæ–‡æ¡£

| æ–‡æ¡£ | å†…å®¹ | é¡µæ•° | ä¼˜å…ˆçº§ |
|------|------|------|--------|
| [00_æŠ€èƒ½å›¾è°±æ€»è§ˆ](./00_æŠ€èƒ½å›¾è°±æ€»è§ˆ.md) | æœ¬æ–‡æ¡£ - å…¨å±€æ¦‚è§ˆ | - | â­ START HERE |
| [06_å²—ä½æ ¸å¿ƒæŠ€èƒ½æ·±åº¦å›¾è°±](./06_å²—ä½æ ¸å¿ƒæŠ€èƒ½æ·±åº¦å›¾è°±.md) | AIæ¨¡å‹ä¸éƒ¨ç½² | ~25é¡µ | â­â­â­â­â­ |
| [07_ç³»ç»Ÿå·¥å…·é“¾ä¸åº•å±‚æŠ€èƒ½](./07_ç³»ç»Ÿå·¥å…·é“¾ä¸åº•å±‚æŠ€èƒ½.md) | Linux/Docker/C++ | ~23é¡µ | â­â­â­â­â­ |
| [08_åº”ç”¨å¼€å‘ä¸è½¯æŠ€èƒ½](./08_åº”ç”¨å¼€å‘ä¸è½¯æŠ€èƒ½.md) | FastAPI/é£ä¹¦/RAG | ~33é¡µ | â­â­â­â­â­ |

### è¾…åŠ©æ–‡æ¡£

| æ–‡æ¡£ | å†…å®¹ | ç”¨é€” |
|------|------|------|
| [01_å²—ä½æŠ€èƒ½åŸ¹è®­è·¯å¾„](./01_å²—ä½æŠ€èƒ½åŸ¹è®­è·¯å¾„.md) | 16å‘¨å­¦ä¹ è®¡åˆ’ | å­¦ä¹ è§„åˆ’ |
| [02_é¡¶çº§è®ºæ–‡ä¸ç ”ç©¶èµ„æº](./02_é¡¶çº§è®ºæ–‡ä¸ç ”ç©¶èµ„æº.md) | 28ç¯‡è®ºæ–‡ + ç ”ç©¶å®¤ | ç†è®ºæ·±å…¥ |
| [03_Kaggleç«èµ›ä¸å®è·µé¡¹ç›®](./03_Kaggleç«èµ›ä¸å®è·µé¡¹ç›®.md) | å®è·µé¡¹ç›® | åŠ¨æ‰‹ç»ƒä¹  |
| [04_AI_Agent_Sandboxæ¶æ„æ–¹æ¡ˆ](./04_AI_Agent_Sandboxæ¶æ„æ–¹æ¡ˆ.md) | åˆ›æ–°é¡¹ç›® | åŠ åˆ†é¡¹ |
| [05_Demoå¼€å‘ä¸å®éªŒæŒ‡å—](./05_Demoå¼€å‘ä¸å®éªŒæŒ‡å—.md) | 3ä¸ªå®Œæ•´Demo | é¡¹ç›®å®æˆ˜ |

---

## ğŸ¯ Tå­—å‹æŠ€èƒ½ä½“ç³»

```infographic
infographic hierarchy-mindmap-curved-line-compact-card
data
  title AIèŠ¯ç‰‡åº”ç”¨å¼€å‘å…¨æ ˆæŠ€èƒ½
  items
    - label æ·±åº¦æŠ€èƒ½ (Tå­—ç«–çº¿)
      children:
        - label æ¨¡å‹éƒ¨ç½²ä¼˜åŒ–
        - label åç«¯å¼€å‘
        - label èŠ¯ç‰‡SDKé›†æˆ
    - label å¹¿åº¦æŠ€èƒ½ (Tå­—æ¨ªçº¿)
      children:
        - label AIæ¨¡å‹ç†è®º
        - label ç³»ç»Ÿå·¥å…·é“¾
        - label åº”ç”¨å¼€å‘
        - label è½¯æŠ€èƒ½
```

---

## ä¸€ã€AIæ¨¡å‹ä¸éƒ¨ç½² (æ·±åº¦æ ¸å¿ƒ)

### 1.1 Transformer & LLMåŸºç¡€

**å¿…é¡»ç†è§£çš„æ¦‚å¿µ** â­â­â­â­â­

```
Self-Attentionæœºåˆ¶
â”œâ”€â”€ Q, K, VçŸ©é˜µè®¡ç®—
â”œâ”€â”€ Multi-Head Attention
â””â”€â”€ è®¡ç®—å¤æ‚åº¦: O(nÂ²)

Position Encoding
â”œâ”€â”€ ç»å¯¹ä½ç½®ç¼–ç 
â””â”€â”€ ç›¸å¯¹ä½ç½®ç¼–ç  (RoPE)

KV Cache â­ æ ¸å¿ƒä¼˜åŒ–
â”œâ”€â”€ ä¸ºä»€ä¹ˆéœ€è¦: é¿å…é‡å¤è®¡ç®—
â”œâ”€â”€ æ˜¾å­˜å ç”¨: ~0.4GB/1000 tokens
â””â”€â”€ åŠ é€Ÿæ¯”: ç†è®ºO(n) vs O(nÂ²)

æ¨ç†å‚æ•°
â”œâ”€â”€ Temperature: æ§åˆ¶éšæœºæ€§
â”œâ”€â”€ Top-P/Top-K: é‡‡æ ·ç­–ç•¥
â””â”€â”€ Repetition Penalty: é˜²æ­¢é‡å¤
```

**å®è·µæŠ€èƒ½**

- [ ] èƒ½å¤Ÿä½¿ç”¨HuggingFace TransformersåŠ è½½æ¨¡å‹
- [ ] ç†è§£config.jsonä¸­çš„å…³é”®å‚æ•°
- [ ] ä¼šè°ƒæ•´æ¨ç†å‚æ•°ä¼˜åŒ–è¾“å‡ºè´¨é‡
- [ ] èƒ½å¤Ÿæµ‹é‡TPSã€TTFTã€ååé‡

**å­¦ä¹ èµ„æº**: `06_å²—ä½æ ¸å¿ƒæŠ€èƒ½æ·±åº¦å›¾è°±.md` ç¬¬1ç« 

---

### 1.2 æ¨¡å‹é‡åŒ–æŠ€æœ¯

**æ•°å€¼ç²¾åº¦å¯¹æ¯”** â­â­â­â­â­

| ç²¾åº¦ | å¤§å° | èŒƒå›´ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| FP32 | 4 bytes | Â±3.4Ã—10Â³â¸ | è®­ç»ƒ |
| FP16 | 2 bytes | Â±65,504 | æ¨ç†åŸºçº¿ |
| BF16 | 2 bytes | Â±3.4Ã—10Â³â¸ | è®­ç»ƒ(TPU) |
| INT8 | 1 byte | -128~127 | æ¨ç†ä¼˜åŒ– |
| INT4 | 0.5 byte | -8~7 | æè‡´å‹ç¼© |

**é‡åŒ–æ–¹æ³•**

```
PTQ (è®­ç»ƒåé‡åŒ–) â† é‡ç‚¹
â”œâ”€â”€ LLM.int8() (bitsandbytes)
â”‚   â”œâ”€â”€ æ··åˆç²¾åº¦: æ•æ„Ÿå±‚ä¿æŒFP16
â”‚   â””â”€â”€ å®ç°: pip install bitsandbytes
â”œâ”€â”€ GPTQ
â”‚   â”œâ”€â”€ INT4é‡åŒ–
â”‚   â””â”€â”€ éœ€è¦æ ¡å‡†æ•°æ®é›†
â””â”€â”€ AWQ (MIT Han Lab)
    â”œâ”€â”€ æ¿€æ´»æ„ŸçŸ¥é‡åŒ–
    â””â”€â”€ SOTAæ€§èƒ½

QAT (é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ)
â””â”€â”€ è®­ç»ƒæ—¶æ¨¡æ‹Ÿé‡åŒ– (ä¸å¸¸ç”¨)
```

**å…³é”®ä»£ç **

```python
# bitsandbytes INT8
from transformers import AutoModel, BitsAndBytesConfig

model = AutoModel.from_pretrained(
    "THUDM/chatglm3-6b",
    quantization_config=BitsAndBytesConfig(load_in_8bit=True),
    device_map="auto"
)
# æ˜¾å­˜: 13.2GB â†’ 7.1GB (â†“46%)
```

**å®è·µæŠ€èƒ½**

- [ ] èƒ½å¤Ÿä½¿ç”¨bitsandbytesè¿›è¡ŒINT8é‡åŒ–
- [ ] ç†è§£é‡åŒ–çš„scaleå’Œzero-pointæ¦‚å¿µ
- [ ] èƒ½å¤Ÿæµ‹é‡é‡åŒ–å‰åçš„æ€§èƒ½/ç²¾åº¦å·®å¼‚
- [ ] äº†è§£GPTQ/AWQçš„åŸç†å’Œä½¿ç”¨

**å­¦ä¹ èµ„æº**: `06_å²—ä½æ ¸å¿ƒæŠ€èƒ½æ·±åº¦å›¾è°±.md` ç¬¬1.2èŠ‚

---

### 1.3 ONNXä¸æ¨¡å‹æ ¼å¼

**ONNXä»·å€¼** â­â­â­â­

```
PyTorchæ¨¡å‹ â†’ ONNX â†’ è‡ªç ”èŠ¯ç‰‡æ¨ç†å¼•æ“
             â†“
        TensorRT/OpenVINO/...

ä¼˜åŠ¿:
âœ… æ¡†æ¶æ— å…³
âœ… ä¼˜åŒ–å›¾ (ç®—å­èåˆã€å¸¸é‡æŠ˜å )
âœ… ç¡¬ä»¶é€‚é… (èŠ¯ç‰‡å‚å•†å®ç°ONNX Runtime)
```

**å®è·µæŠ€èƒ½**

- [ ] èƒ½å¤Ÿå°†PyTorchæ¨¡å‹å¯¼å‡ºä¸ºONNX
- [ ] ä¼šä½¿ç”¨NetronæŸ¥çœ‹æ¨¡å‹ç»“æ„
- [ ] èƒ½å¤Ÿä½¿ç”¨ONNX Runtimeè¿›è¡Œæ¨ç†
- [ ] ç†è§£dynamic_axesçš„ä½œç”¨

**å­¦ä¹ èµ„æº**: `06_å²—ä½æ ¸å¿ƒæŠ€èƒ½æ·±åº¦å›¾è°±.md` ç¬¬1.3èŠ‚

---

## äºŒã€ç³»ç»Ÿå·¥å…·é“¾ (å¹¿åº¦åŸºç¡€)

### 2.1 Linuxç³»ç»Ÿç®¡ç†

**æ ¸å¿ƒå‘½ä»¤** â­â­â­â­â­

```bash
# æ–‡ä»¶æƒé™
chmod 755 script.sh
chown user:group file.txt

# è¿›ç¨‹ç®¡ç†
ps aux | grep python
kill -9 PID
htop  # äº¤äº’å¼ç›‘æ§

# èµ„æºç›‘æ§
nvidia-smi  # GPU
top / htop  # CPU/å†…å­˜
df -h  # ç£ç›˜

# æ—¥å¿—åˆ†æ
tail -f server.log
grep -C 5 "ERROR" server.log
```

**Shellè„šæœ¬èƒ½åŠ›**

- [ ] èƒ½å¤Ÿç¼–å†™è‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬
- [ ] ç†è§£ç®¡é“ã€é‡å®šå‘ã€åå°è¿è¡Œ
- [ ] ä¼šä½¿ç”¨tmux/screenç®¡ç†ä¼šè¯
- [ ] èƒ½å¤Ÿæ’æŸ¥å¸¸è§ç³»ç»Ÿé—®é¢˜

**å­¦ä¹ èµ„æº**: `07_ç³»ç»Ÿå·¥å…·é“¾ä¸åº•å±‚æŠ€èƒ½.md` ç¬¬2.1èŠ‚

---

### 2.2 Dockerå®¹å™¨åŒ–

**ä¸ºä»€ä¹ˆDockerå¯¹AIèŠ¯ç‰‡å¼€å‘æå…¶é‡è¦?** â­â­â­â­â­

```
AIèŠ¯ç‰‡ç¯å¢ƒå¤æ‚æ€§:
â”œâ”€â”€ èŠ¯ç‰‡é©±åŠ¨: ç‰¹å®šç‰ˆæœ¬
â”œâ”€â”€ CUDA/ROCm: ä¸é©±åŠ¨å¼ºç»‘å®š
â”œâ”€â”€ æ·±åº¦å­¦ä¹ æ¡†æ¶: ä¾èµ–ç‰¹å®šç¼–è¯‘åº“
â””â”€â”€ Pythonä¾èµ–: æ•°ç™¾ä¸ªåŒ…

Dockerè§£å†³:
âœ… ç¯å¢ƒä¸€è‡´æ€§
âœ… å¿«é€Ÿéƒ¨ç½²
âœ… éš”ç¦»æ€§
âœ… ç‰ˆæœ¬æ§åˆ¶
```

**æ ¸å¿ƒæŠ€èƒ½**

```bash
# åŸºç¡€æ“ä½œ
docker run -it --gpus all -v $(pwd):/workspace pytorch/pytorch bash
docker ps
docker exec -it container_name bash

# é•œåƒæ„å»º
docker build -t chip-inference:v1.0 .
docker push

# ç¼–æ’
docker-compose up -d
```

**Dockerfileæœ€ä½³å®è·µ**

```dockerfile
FROM pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY src/ ./src/
EXPOSE 8000

CMD ["uvicorn", "src.server:app", "--host", "0.0.0.0"]
```

**å®è·µæŠ€èƒ½**

- [ ] èƒ½å¤Ÿç¼–å†™Dockerfile
- [ ] ç†è§£é•œåƒå±‚ç¼“å­˜æœºåˆ¶
- [ ] ä¼šä½¿ç”¨docker-composeç¼–æ’æœåŠ¡
- [ ] èƒ½å¤Ÿè¿›è¡Œå®¹å™¨è°ƒè¯•

**å­¦ä¹ èµ„æº**: `07_ç³»ç»Ÿå·¥å…·é“¾ä¸åº•å±‚æŠ€èƒ½.md` ç¬¬2.2èŠ‚

---

### 2.3 C++åŸºç¡€é˜…è¯»

**ä¸ºä»€ä¹ˆéœ€è¦C++?** â­â­â­

```
AIèŠ¯ç‰‡SDK:
â”œâ”€â”€ é©±åŠ¨å±‚: C/C++
â”œâ”€â”€ ç®—å­åº“: CUDA C++
â”œâ”€â”€ Pythonç»‘å®š: pybind11
â””â”€â”€ æ„å»ºç³»ç»Ÿ: CMake

éœ€è¦èƒ½åŠ›:
âœ… é˜…è¯»SDKæ–‡æ¡£å’Œç¤ºä¾‹
âœ… çœ‹æ‡‚æŠ¥é”™ä¿¡æ¯
âœ… ä¿®æ”¹CMakeLists.txt
âœ… ç¼–è¯‘C++æ‰©å±•
```

**å¿…å¤‡çŸ¥è¯†**

```cpp
// æŒ‡é’ˆä¸æ™ºèƒ½æŒ‡é’ˆ
std::unique_ptr<Model> model;
std::shared_ptr<Tensor> tensor;

// ç±»ä¸å¯¹è±¡
class InferenceEngine {
public:
    InferenceEngine(const std::string& path);
    Tensor forward(const Tensor& input);
private:
    std::shared_ptr<Model> model_;
};

// pybind11ç»‘å®š
PYBIND11_MODULE(chip_inference, m) {
    py::class_<Model>(m, "Model")
        .def(py::init<const std::string&>())
        .def("inference", &Model::inference);
}
```

**CMakeåŸºç¡€**

```cmake
cmake_minimum_required(VERSION 3.18)
project(ChipInference)

find_package(CUDA REQUIRED)
find_package(Python3 REQUIRED)

add_library(chip_inference SHARED src/model.cpp)
target_link_libraries(chip_inference ${CUDA_LIBRARIES})
```

**å®è·µæŠ€èƒ½**

- [ ] èƒ½å¤Ÿé˜…è¯»C++ SDKç¤ºä¾‹ä»£ç 
- [ ] ç†è§£å¸¸è§æŠ¥é”™ä¿¡æ¯
- [ ] ä¼šä¿®æ”¹CMakeLists.txté…ç½®
- [ ] èƒ½å¤Ÿç¼–è¯‘ç®€å•çš„C++æ‰©å±•

**å­¦ä¹ èµ„æº**: `07_ç³»ç»Ÿå·¥å…·é“¾ä¸åº•å±‚æŠ€èƒ½.md` ç¬¬2.3èŠ‚

---

## ä¸‰ã€åº”ç”¨å¼€å‘ (æ·±åº¦æ ¸å¿ƒ)

### 3.1 FastAPIåç«¯å¼€å‘

**æ ¸å¿ƒæ¶æ„** â­â­â­â­â­

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class GenerateRequest(BaseModel):
    prompt: str
    max_tokens: int = 512

@app.post("/generate")
async def generate(request: GenerateRequest):
    # å¼‚æ­¥æ¨ç†
    result = await model_manager.generate(request)
    return result

# è‡ªåŠ¨ç”ŸæˆAPIæ–‡æ¡£: /docs
```

**å…³é”®ç‰¹æ€§**

```
âœ… å¼‚æ­¥æ”¯æŒ (async/await)
âœ… ç±»å‹æç¤º + æ•°æ®éªŒè¯ (Pydantic)
âœ… è‡ªåŠ¨APIæ–‡æ¡£ (Swagger UI)
âœ… é«˜æ€§èƒ½ (Starlette + uvicorn)
```

**å¼‚æ­¥ç¼–ç¨‹**

```python
# å¹¶å‘æ¨ç†
async def batch_inference(prompts):
    tasks = [generate(p) for p in prompts]
    return await asyncio.gather(*tasks)

# è¶…æ—¶æ§åˆ¶
result = await asyncio.wait_for(
    generate(prompt),
    timeout=30.0
)
```

**å®è·µæŠ€èƒ½**

- [ ] èƒ½å¤Ÿä½¿ç”¨FastAPIæ„å»ºAPIæœåŠ¡
- [ ] ç†è§£async/awaitå¼‚æ­¥ç¼–ç¨‹
- [ ] ä¼šä½¿ç”¨Pydanticè¿›è¡Œæ•°æ®éªŒè¯
- [ ] èƒ½å¤Ÿæ·»åŠ ä¸­é—´ä»¶ã€é”™è¯¯å¤„ç†

**å­¦ä¹ èµ„æº**: `08_åº”ç”¨å¼€å‘ä¸è½¯æŠ€èƒ½.md` ç¬¬3.1èŠ‚

---

### 3.2 é£ä¹¦å¼€æ”¾å¹³å°

**æ ¸å¿ƒæµç¨‹** â­â­â­â­â­

```
ç”¨æˆ·æ¶ˆæ¯ â†’ é£ä¹¦æœåŠ¡å™¨ â†’ Webhookå›è°ƒ â†’ ä½ çš„æœåŠ¡
                                        â†“
                               AIç”Ÿæˆå›å¤
                                        â†“
           é£ä¹¦API â† å‘é€æ¶ˆæ¯ â† ä½ çš„æœåŠ¡
```

**OAuth 2.0é‰´æƒ**

```python
# è·å–tenant_access_token
response = requests.post(
    "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal",
    json={"app_id": APP_ID, "app_secret": APP_SECRET}
)
token = response.json()["tenant_access_token"]

# ä½¿ç”¨token
headers = {"Authorization": f"Bearer {token}"}
```

**äº‹ä»¶å¤„ç†**

```python
@app.post("/feishu/webhook")
async def feishu_webhook(request: Request):
    body = await request.json()
    
    # URLéªŒè¯
    if "challenge" in body:
        return {"challenge": body["challenge"]}
    
    # å¤„ç†æ¶ˆæ¯
    if event_type == "im.message.receive_v1":
        user_input = parse_message(body)
        ai_response = await generate_response(user_input)
        await send_message(chat_id, ai_response)
    
    return {"code": 0}
```

**äº¤äº’å¼å¡ç‰‡**

```python
card = {
    "header": {"title": {"content": "AIåŠ©æ‰‹"}},
    "elements": [
        {"tag": "div", "text": {"content": answer}},
        {
            "tag": "action",
            "actions": [
                {"tag": "button", "text": {"content": "ğŸ‘"}}
            ]
        }
    ]
}
```

**å®è·µæŠ€èƒ½**

- [ ] èƒ½å¤Ÿæ³¨å†Œé£ä¹¦å¼€å‘è€…è´¦å·
- [ ] ç†è§£OAuth 2.0é‰´æƒæµç¨‹
- [ ] ä¼šå¤„ç†æ¶ˆæ¯äº‹ä»¶å’Œå¡ç‰‡äº¤äº’
- [ ] èƒ½å¤Ÿè°ƒè¯•Webhookå›è°ƒ

**å­¦ä¹ èµ„æº**: `08_åº”ç”¨å¼€å‘ä¸è½¯æŠ€èƒ½.md` ç¬¬3.2èŠ‚

---

### 3.3 RAGæ£€ç´¢å¢å¼ºç”Ÿæˆ

**æ¶æ„åŸç†** â­â­â­â­â­

```
ç”¨æˆ·é—®é¢˜
  â†“
Embeddingç¼–ç 
  â†“
å‘é‡æ£€ç´¢ (FAISS/Milvus)
  â†“
å¬å›Top-Kç›¸å…³æ–‡æ¡£
  â†“
ç»„åˆæˆPrompt
  â†“
LLMç”Ÿæˆå›ç­” (å¸¦æ¥æº)
```

**æ ¸å¿ƒç»„ä»¶**

```python
# 1. Embedding
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('BAAI/bge-small-zh-v1.5')
embedding = model.encode(["AIèŠ¯ç‰‡"])

# 2. å‘é‡å­˜å‚¨ (FAISS)
import faiss
index = faiss.IndexFlatIP(512)  # 512ç»´
index.add(embeddings)

# 3. æ£€ç´¢
scores, indices = index.search(query_embedding, k=3)

# 4. æ–‡æ¡£åˆ‡ç‰‡
from langchain.text_splitter import RecursiveCharacterTextSplitter
splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50
)
chunks = splitter.split_text(document)
```

**å®Œæ•´æµç¨‹**

```python
class RAGSystem:
    def __init__(self, kb_path):
        # åŠ è½½çŸ¥è¯†åº“
        documents = load_documents(kb_path)
        chunks = split_documents(documents)
        self.vector_store = create_index(chunks)
    
    async def answer(self, question):
        # æ£€ç´¢
        docs = self.vector_store.search(question, k=3)
        
        # æ„å»ºprompt
        context = "\n".join([doc.content for doc in docs])
        prompt = f"åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”:\n{context}\n\né—®é¢˜:{question}"
        
        # LLMç”Ÿæˆ
        answer = await llm.generate(prompt)
        
        return {"answer": answer, "sources": docs}
```

**å®è·µæŠ€èƒ½**

- [ ] ç†è§£Embeddingå’Œå‘é‡æ£€ç´¢åŸç†
- [ ] èƒ½å¤Ÿä½¿ç”¨FAISSæ„å»ºå‘é‡ç´¢å¼•
- [ ] ä¼šè¿›è¡Œæ–‡æ¡£åˆ‡ç‰‡(chunking)
- [ ] èƒ½å¤Ÿæ„å»ºå®Œæ•´çš„RAGç³»ç»Ÿ

**å­¦ä¹ èµ„æº**: `08_åº”ç”¨å¼€å‘ä¸è½¯æŠ€èƒ½.md` ç¬¬3.3èŠ‚

---

## å››ã€è½¯æŠ€èƒ½ (å¿…å¤‡)

### 4.1 æŠ€æœ¯æ–‡æ¡£æ’°å†™

**APIæ–‡æ¡£æ¨¡æ¿** â­â­â­â­

```markdown
## æ¥å£åç§°

**æè¿°**: xxx

**è¯·æ±‚**
POST /api/endpoint
Content-Type: application/json

{
  "param1": "value1"
}

**å‚æ•°è¯´æ˜**
| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|------|------|------|------|
| param1 | string | æ˜¯ | xxx |

**å“åº”ç¤ºä¾‹**
{
  "code": 0,
  "data": {}
}

**é”™è¯¯ç **
| ç  | è¯´æ˜ | è§£å†³ |
|----|------|------|
| 400 | å‚æ•°é”™è¯¯ | xxx |
```

**æµ‹è¯•æŠ¥å‘Šæ¨¡æ¿**

```markdown
# æ€§èƒ½æµ‹è¯•æŠ¥å‘Š

## æµ‹è¯•ç¯å¢ƒ
- GPU: xxx
- ç³»ç»Ÿ: xxx

## æµ‹è¯•æ–¹æ³•
xxx

## æµ‹è¯•ç»“æœ
| é…ç½® | æ˜¾å­˜ | é€Ÿåº¦ |
|------|------|------|
| FP16 | 13GB | 45tok/s |
| INT8 | 7GB | 52tok/s |

## ç»“è®º
xxx
```

---

### 4.2 æµ‹è¯•æ–¹æ³•è®º

**æ§åˆ¶å˜é‡æ³•** â­â­â­â­

```
æµ‹è¯•é‡åŒ–æ•ˆæœæ—¶:
âœ… æ§åˆ¶: æ¨¡å‹ã€æ•°æ®é›†ã€ç¡¬ä»¶
âœ… å˜é‡: ä»…ç²¾åº¦ (FP16 vs INT8)

æµ‹è¯•æ¨ç†åŠ é€Ÿæ—¶:
âœ… æ§åˆ¶: æ¨¡å‹ã€ç²¾åº¦ã€è¾“å…¥
âœ… å˜é‡: æ¨ç†å¼•æ“ (PyTorch vs vLLM)
```

**Edge Caseæ€ç»´**

```python
# è€ƒè™‘æç«¯æƒ…å†µ
- ç©ºè¾“å…¥: prompt = ""
- è¶…é•¿è¾“å…¥: prompt = "x" * 10000
- ç‰¹æ®Šå­—ç¬¦: prompt = "ğŸ¤–ğŸ’»\n\t"
- å¹¶å‘: 1000ä¸ªåŒæ—¶è¯·æ±‚
```

---

## ğŸ¯ å­¦ä¹ ä¼˜å…ˆçº§çŸ©é˜µ

```infographic
infographic quadrant-quarter-simple-card
data
  title æŠ€èƒ½å­¦ä¹ ä¼˜å…ˆçº§
  items
    - label ç¬¬ä¸€ä¼˜å…ˆçº§ (ç”Ÿå­˜æŠ€èƒ½)
      desc Python + Linux + æ¨¡å‹éƒ¨ç½²åŸºç¡€
      quadrant 1
    - label ç¬¬äºŒä¼˜å…ˆçº§ (ä¸šåŠ¡æŠ€èƒ½)
      desc é£ä¹¦å¼€å‘ + RAG
      quadrant 2
    - label ç¬¬ä¸‰ä¼˜å…ˆçº§ (è¿›é˜¶æŠ€èƒ½)
      desc Docker + é‡åŒ– + C++
      quadrant 3
    - label ç¬¬å››ä¼˜å…ˆçº§ (åŠ åˆ†é¡¹)
      desc Agent Sandbox + è®ºæ–‡é˜…è¯»
      quadrant 4
```

---

## ğŸ“… 16å‘¨å­¦ä¹ æ—¶é—´çº¿

```infographic
infographic sequence-timeline-simple
data
  title å®Œæ•´å­¦ä¹ è·¯å¾„
  items
    - label Week 1-4
      desc åŸºç¡€: Linux/Python/PyTorch/Transformer
    - label Week 5-8
      desc éƒ¨ç½²: é‡åŒ–/ONNX/Docker/æ€§èƒ½æµ‹è¯•
    - label Week 9-12
      desc å¤§æ¨¡å‹: LLMéƒ¨ç½²/ä¼˜åŒ–/FastAPI
    - label Week 13-16
      desc åº”ç”¨: é£ä¹¦Bot/RAG/å®Œæ•´é¡¹ç›®
```

---

## âœ… æŠ€èƒ½è‡ªæ£€æ¸…å•

### AIæ¨¡å‹ä¸éƒ¨ç½²

- [ ] ç†è§£Transformeræ¶æ„å’Œattentionæœºåˆ¶
- [ ] ç†è§£KV Cacheçš„ä½œç”¨å’Œå®ç°
- [ ] èƒ½å¤Ÿè°ƒæ•´æ¨ç†å‚æ•°(temperature, top_p)
- [ ] æŒæ¡bitsandbytes INT8é‡åŒ–
- [ ] äº†è§£GPTQ/AWQé‡åŒ–æ–¹æ³•
- [ ] èƒ½å¤Ÿå¯¼å‡ºå’Œä½¿ç”¨ONNXæ¨¡å‹
- [ ] ä¼šæµ‹é‡TPSã€TTFTã€ååé‡

### ç³»ç»Ÿå·¥å…·é“¾

- [ ] ç†Ÿç»ƒä½¿ç”¨Linuxå‘½ä»¤è¡Œ
- [ ] èƒ½å¤Ÿç¼–å†™Shellè‡ªåŠ¨åŒ–è„šæœ¬
- [ ] æŒæ¡DockeråŸºç¡€æ“ä½œ
- [ ] èƒ½å¤Ÿç¼–å†™Dockerfile
- [ ] ä¼šä½¿ç”¨docker-composeç¼–æ’
- [ ] èƒ½å¤Ÿé˜…è¯»C++ SDKä»£ç 
- [ ] ç†è§£CMakeåŸºç¡€

### åº”ç”¨å¼€å‘

- [ ] èƒ½å¤Ÿä½¿ç”¨FastAPIæ„å»ºAPI
- [ ] ç†è§£async/awaitå¼‚æ­¥ç¼–ç¨‹
- [ ] æŒæ¡é£ä¹¦OAuth 2.0é‰´æƒ
- [ ] èƒ½å¤Ÿå¤„ç†é£ä¹¦æ¶ˆæ¯äº‹ä»¶
- [ ] ä¼šæ„å»ºäº¤äº’å¼å¡ç‰‡
- [ ] ç†è§£RAGæ¶æ„åŸç†
- [ ] èƒ½å¤Ÿä½¿ç”¨FAISSè¿›è¡Œå‘é‡æ£€ç´¢
- [ ] ä¼šè¿›è¡Œæ–‡æ¡£åˆ‡ç‰‡å’ŒEmbedding

### è½¯æŠ€èƒ½

- [ ] èƒ½å¤Ÿæ’°å†™æ¸…æ™°çš„APIæ–‡æ¡£
- [ ] ä¼šç¼–å†™æµ‹è¯•æŠ¥å‘Š
- [ ] å…·å¤‡æ§åˆ¶å˜é‡æ³•æ€ç»´
- [ ] è€ƒè™‘Edge Case

---

## ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—

### Day 1: ç¯å¢ƒå‡†å¤‡

```bash
# 1. å®‰è£…Conda
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh

# 2. åˆ›å»ºç¯å¢ƒ
conda create -n chip-dev python=3.10
conda activate chip-dev

# 3. å®‰è£…PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 4. å®‰è£…åŸºç¡€åº“
pip install transformers accelerate bitsandbytes fastapi uvicorn
```

### Week 1: ç¬¬ä¸€ä¸ªæ¨¡å‹

```python
# hello_llm.py
from transformers import AutoModel, AutoTokenizer

model_name = "THUDM/chatglm3-6b"
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
model = AutoModel.from_pretrained(model_name, trust_remote_code=True).cuda()

response, history = model.chat(tokenizer, "ä½ å¥½", history=[])
print(response)
```

### Week 4: ç¬¬ä¸€ä¸ªAPI

```python
# server.py
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class Request(BaseModel):
    prompt: str

@app.post("/generate")
async def generate(req: Request):
    # è°ƒç”¨æ¨¡å‹
    response = model.chat(tokenizer, req.prompt)[0]
    return {"text": response}

# è¿è¡Œ: uvicorn server:app --reload
```

---

## ğŸ“– æ¨èé˜…è¯»é¡ºåº

**æ–°æ‰‹è·¯å¾„** (ç¬¬1-4å‘¨)
1. `01_å²—ä½æŠ€èƒ½åŸ¹è®­è·¯å¾„.md` - äº†è§£å…¨å±€
2. `06_å²—ä½æ ¸å¿ƒæŠ€èƒ½æ·±åº¦å›¾è°±.md` ç¬¬1.1èŠ‚ - TransformeråŸºç¡€
3. åŠ¨æ‰‹: åŠ è½½ç¬¬ä¸€ä¸ªæ¨¡å‹
4. `07_ç³»ç»Ÿå·¥å…·é“¾ä¸åº•å±‚æŠ€èƒ½.md` ç¬¬2.1èŠ‚ - LinuxåŸºç¡€

**è¿›é˜¶è·¯å¾„** (ç¬¬5-12å‘¨)
5. `06_å²—ä½æ ¸å¿ƒæŠ€èƒ½æ·±åº¦å›¾è°±.md` ç¬¬1.2èŠ‚ - é‡åŒ–æŠ€æœ¯
6. åŠ¨æ‰‹: INT8é‡åŒ–å®éªŒ
7. `07_ç³»ç»Ÿå·¥å…·é“¾ä¸åº•å±‚æŠ€èƒ½.md` ç¬¬2.2èŠ‚ - Docker
8. åŠ¨æ‰‹: å®¹å™¨åŒ–éƒ¨ç½²
9. `08_åº”ç”¨å¼€å‘ä¸è½¯æŠ€èƒ½.md` ç¬¬3.1èŠ‚ - FastAPI
10. åŠ¨æ‰‹: æ„å»ºæ¨ç†API

**å®æˆ˜è·¯å¾„** (ç¬¬13-16å‘¨)
11. `08_åº”ç”¨å¼€å‘ä¸è½¯æŠ€èƒ½.md` ç¬¬3.2èŠ‚ - é£ä¹¦å¼€å‘
12. `08_åº”ç”¨å¼€å‘ä¸è½¯æŠ€èƒ½.md` ç¬¬3.3èŠ‚ - RAG
13. åŠ¨æ‰‹: é£ä¹¦AIæœºå™¨äºº
14. `05_Demoå¼€å‘ä¸å®éªŒæŒ‡å—.md` - å®Œæ•´é¡¹ç›®
15. `02_é¡¶çº§è®ºæ–‡ä¸ç ”ç©¶èµ„æº.md` - ç†è®ºæ·±åŒ–

---

## ğŸ’¡ å­¦ä¹ å»ºè®®

### æ—¶é—´åˆ†é…

```
æ¯å¤©4å°æ—¶å­¦ä¹ :
â”œâ”€â”€ 2å°æ—¶: ç†è®ºå­¦ä¹  (çœ‹æ–‡æ¡£/è§†é¢‘)
â”œâ”€â”€ 1.5å°æ—¶: åŠ¨æ‰‹å®è·µ (å†™ä»£ç )
â””â”€â”€ 0.5å°æ—¶: æ€»ç»“ç¬”è®°
```

### å­¦ä¹ æ–¹æ³•

1. **ç†è®ºä¸å®è·µç»“åˆ**: çœ‹ä¸€èŠ‚æ–‡æ¡£,å†™ä¸€æ®µä»£ç 
2. **è´¹æ›¼æŠ€å·§**: èƒ½ç”¨è‡ªå·±çš„è¯è®²ç»™åˆ«äººå¬
3. **åˆ»æ„ç»ƒä¹ **: æ‰¾ä¸ä¼šçš„åå¤ç»ƒ
4. **é¡¹ç›®é©±åŠ¨**: ä»¥3ä¸ªDemoä¸ºç›®æ ‡
5. **è®°å½•æˆé•¿**: GitHub + æŠ€æœ¯åšå®¢

---

## ğŸ“ æœ€ç»ˆç›®æ ‡

**16å‘¨åä½ å°†å…·å¤‡**:

âœ… **ç†è®ºçŸ¥è¯†**
- Transformeræ¶æ„æ·±åº¦ç†è§£
- é‡åŒ–ã€æ¨ç†ä¼˜åŒ–åŸç†
- RAGç³»ç»Ÿè®¾è®¡

âœ… **å®è·µæŠ€èƒ½**
- æ¨¡å‹éƒ¨ç½²ä¸ä¼˜åŒ–
- åç«¯APIå¼€å‘
- é£ä¹¦åº”ç”¨é›†æˆ
- å‘é‡æ£€ç´¢ç³»ç»Ÿ

âœ… **é¡¹ç›®ä½œå“**
- å¤§æ¨¡å‹éƒ¨ç½²ä¼˜åŒ– (æ€§èƒ½æŠ¥å‘Š)
- é£ä¹¦AIæœºå™¨äºº (å¯æ¼”ç¤º)
- Agent SandboxåŸå‹ (åˆ›æ–°é¡¹ç›®)

âœ… **è½¯å®åŠ›**
- æŠ€æœ¯æ–‡æ¡£æ’°å†™
- é—®é¢˜æ’æŸ¥èƒ½åŠ›
- ç³»ç»Ÿè®¾è®¡æ€ç»´

---
